üß† AI Code Detection System: Unveiling Code Authorship
üöÄ Overview
The AI Code Detection System is an advanced, neural network-powered application designed to accurately identify whether a given code snippet was written by a human developer or generated by an Artificial Intelligence model. Going beyond simple binary classification, this system provides nuanced insights into code authorship, including detection of "AI Refined Human" or "Human Refined AI" code, and offers detailed metrics on various aspects of code generation.

This project aims to address the growing challenge of distinguishing between human and AI-generated code in an era of powerful Large Language Models (LLMs) and AI-assisted development tools.

‚ú® Key Features
Nuanced Authorship Classification: Distinguishes between:

Human Generated: High confidence the code is purely human-written.

AI Generated: High confidence the code is primarily AI-generated.

Human Refined AI: Code likely started by AI, then significantly modified/improved by a human.

AI Refined Human: Code likely started by a human, then processed/optimized by an AI.

Undetectable AI / Undetectable Human / Ambiguous/Mixed: For cases where the model cannot confidently attribute authorship due to high similarity or very subtle characteristics.

Comprehensive Feature Engineering: Utilizes 49 meticulously engineered features that capture deep structural, lexical, and stylistic patterns in code, making the model robust even when comments are absent. Features include:

Code size and line counts.

Indentation consistency and whitespace patterns.

Function/class definitions, loops, and conditionals.

Operator and literal counts.

Cyclomatic complexity proxy.

Average identifier and token lengths.

Nesting depth of blocks and parentheses.

Specific AI-generated API boilerplate detection (e.g., TensorFlow/Keras patterns).

New complexity features: Logical/comparison operator counts, ratio of nested conditionals.

And many more, designed to differentiate subtle coding "fingerprints."

Deep Neural Network Architecture: Powered by a multi-layer perceptron (MLPClassifier) with a robust hidden layer configuration (e.g., (128, 64, 32)), capable of learning complex relationships within the high-dimensional feature space.

Robust Data Handling: Integrates real-world human and AI-generated code datasets from GitHub, augmented with a diverse set of hardcoded synthetic AI code snippets to enhance training robustness and cover various programming languages and coding styles.

Precise Probability Ratios: Outputs floating-point probabilities for AI and Human likelihoods, capped at a maximum of 98% (or a configurable value) and a minimum of 1% to reflect the inherent non-absolute nature of authorship detection and avoid overconfidence. Probabilities are displayed with high precision (e.g., 4 decimal places).

Detailed Feature Insights: Provides qualitative and semi-quantitative insights into various aspects of the code's generation, such as:

Code Style Rate: (Excellent, Good, Poor) based on indentation, blank lines, identifier length.

Complexity Rate: (Very High, High, Medium, Low) based on cyclomatic complexity, function length, logical/comparison operators, nested conditionals.

Boilerplate Tendency: (High, Low) based on import, class, and function counts.

Readability: (High, Low) based on short/long line ratios and original comment presence.

Specific AI Pattern: (e.g., TensorFlow/Keras Boilerplate Detected).

User-Friendly Frontend (Conceptual): Designed to connect with a web-based UI that provides intuitive input methods (paste code, file upload) and visually rich analysis results, including the nuanced labels, precise probabilities, and detailed feature insights.

‚öôÔ∏è How It Works (Technical Deep Dive)
The system operates in several integrated stages:

Data Acquisition & Preparation:

Real-world Data: The model is trained on a foundational dataset sourced from GitHub CSVs (AI-Human-Generated-Program-Code-Dataset(1).csv, AI-Human-Generated-Program-Code-Dataset(2).csv), containing both human-written and AI-generated code snippets.

Synthetic Data Augmentation: To enhance robustness and cover a wider range of AI-generated patterns across various programming languages, a diverse set of hardcoded synthetic AI code snippets are integrated into the training data. This ensures consistent and fast data availability without external API dependencies during development.

(For large-scale deployment, this step would involve streaming massive datasets like FormAI-Dataset for AI-generated C code or CodeParrot/github-code for human-written code, leveraging tools like Hugging Face datasets library for efficient processing.)

Feature Extraction (extract_features function):

For every code snippet, this crucial function extracts 49 distinct numerical features.

Comment & String Removal: Before most feature calculations, comments and string literals are removed to ensure the analysis focuses on the executable logic and structural patterns, making it robust to superficial changes.

Feature Categories: These features span:

Basic Metrics: Length, line counts, character ratios.

Structural Metrics: Function/class definitions, import counts, indentation.

Lexical Metrics: Word length, unique word ratio, operator/punctuator counts.

Complexity Metrics: Cyclomatic complexity proxy, nesting depth, logical/comparison operator counts, nested conditional ratios.

Stylistic Metrics: Uppercase ratio, blank line ratio, magic number ratio.

Domain-Specific Patterns: Boolean flags for recognizing specific AI-generated boilerplate (e.g., TensorFlow/Keras API usage).

The extracted features are returned as a dictionary, then converted into a consistent NumPy array using FEATURE_ORDER for the machine learning model.

Model Training (MLPClassifier):

A StandardScaler is used to normalize the extracted features, ensuring that no single feature dominates the model's learning due to its scale.

A LabelEncoder converts the "AI" and "Human" labels into numerical representations.

The MLPClassifier (a feed-forward neural network) is trained on the scaled features and encoded labels. It utilizes multiple hidden layers (e.g., (128, 64, 32)) with relu activation and adam optimizer to learn complex non-linear decision boundaries. EarlyStopping is employed to prevent overfitting.

Prediction & Nuanced Interpretation (predict_code_type function):

When a new code snippet is submitted, its features are extracted and scaled.

The trained MLPClassifier predicts the raw probabilities for "AI" and "Human" authorship.

Probability Capping: These raw probabilities are then capped (e.g., 0.98 max, 0.01 min) to ensure no absolute 100% or 0% is reported, reflecting real-world uncertainty.

Nuanced Labeling Logic: A sophisticated heuristic layer analyzes these capped probabilities and specific feature insights (like has_tf_keras_boilerplate, indent_consistency, complexity) to assign one of the detailed nuanced_label categories. This allows the model to make more informed decisions even for ambiguous cases.

Feature Insights Generation: Simultaneously, the feature_insights dictionary is populated with qualitative assessments and ratios based on the extracted features, providing a comprehensive "report card" on the code's characteristics.

üõ†Ô∏è Setup and Usage (High-Level)
To get this project running:

Clone the Repository:

git clone [YOUR_REPO_URL]
cd [YOUR_REPO_NAME]

Install Dependencies:

pip install scikit-learn numpy pandas aiohttp

(Note: For full-scale data integration or if you choose to re-enable dynamic synthetic data generation via LLM APIs, additional libraries like sentence-transformers or py7zr might be required, along with API key configuration.)

Ensure Model Files: The model.py script will generate newly_trained_neural_model.pkl, newly_trained_scaler.pkl, and newly_trained_label_encoder.pkl after its first successful run. These are your trained models.

Run the Backend: Execute your model.py script (or integrate its core logic into a Flask/FastAPI application).

Serve the Frontend: Use a web server to serve enhanced_index.html (or your integrated frontend).

üí° Future Enhancements
Larger, Diverse Datasets: Integrate massive public code datasets (e.g., FormAI-Dataset, codeparrot/github-code) for more robust training across more languages and coding styles.

Semantic Code Analysis: Incorporate advanced NLP techniques (e.g., code embeddings, transformer models fine-tuned for code) to understand code semantics, not just syntax, for even finer-grained detection.

AI Tool Attribution: Develop models capable of identifying which specific AI tool (e.g., ChatGPT, Gemini, Copilot, QuillBot) generated or refined the code, requiring highly specialized datasets and models.

Real-time Analysis: Optimize the model and deployment for low-latency, real-time code analysis in IDEs or CI/CD pipelines.

User Feedback Loop: Implement a mechanism for users to provide feedback on predictions, allowing for continuous model improvement.
